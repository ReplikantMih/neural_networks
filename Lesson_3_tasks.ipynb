{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit\n",
    "\n",
    "from random import choice\n",
    "import dill\n",
    "import traceback\n",
    "import logging\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Task_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Попробуйте улучшить работу нейронной сети(разобранную на уроке) обучавшейся на датасет Fashion-MNIST. Опишите в комментарии к уроку - какого результата вы добились от нейросети? Что помогло вам улучшить ее точность?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def build_model(layers_number, \n",
    "                activation,\n",
    "                neurons_in_layer):\n",
    "    layers = [keras.layers.Flatten(input_shape=(28, 28))]\n",
    "    for i in range(layers_number):\n",
    "        layers.append(keras.layers.Dense(neurons_in_layer, activation=activation))\n",
    "    layers.append(keras.layers.Dense(10))\n",
    "    model = keras.Sequential(layers)\n",
    "    return model\n",
    "\n",
    "def learn(model, \n",
    "          optimizer,\n",
    "          metrics: list,\n",
    "          epochs: int):\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=metrics)\n",
    "\n",
    "    model.fit(train_images, train_labels, epochs=epochs,  verbose=1)\n",
    "    \n",
    "def evaluate(trained_model):\n",
    "    test_loss, test_acc = trained_model.evaluate(test_images,  test_labels, verbose=2)\n",
    "    return round(test_acc, 4)\n",
    "\n",
    "def learn_evaluate_many_times(model, \n",
    "                              optimizer,\n",
    "                              metrics: list,\n",
    "                              epochs: int,\n",
    "                              runs=5):\n",
    "    accuracies = []\n",
    "    weights_path = 'weights.weights'\n",
    "    model.save_weights(weights_path)\n",
    "    \n",
    "    for i in range(runs):\n",
    "        model.load_weights(weights_path)\n",
    "        learn(model=model, \n",
    "              optimizer=optimizer,\n",
    "              metrics=metrics,\n",
    "              epochs=epochs)\n",
    "        accuracies.append(evaluate(model))\n",
    "    accuracies = np.array(accuracies)\n",
    "    return (accuracies.mean(), round(accuracies.std(), 4), accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "results = learn_evaluate_many_times(model=model, \n",
    "                          optimizer='adam',\n",
    "                          metrics=['accuracy'],\n",
    "                          epochs=5,\n",
    "                          runs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Baseline metrics (mean accuracy, accuracy std):  (0.8704, 0.0049)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Research:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Рандомлю комбинации значений параметров и оцениваю на отложенной выборке результаты (по метрике среднее значение accuracy за 5 прогонов и std этой метрики за эти 5 прогонов)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "epochs = np.arange(5, 15, 1)\n",
    "epochs_ = []\n",
    "\n",
    "neurons_numbers = np.arange(1, 325, 5)\n",
    "neurons_numbers_ = []\n",
    "\n",
    "layers_numbers = np.arange(1, 5, 1)\n",
    "layers_numbers_ = []\n",
    "\n",
    "activations = ['relu', 'softmax', 'sigmoid']\n",
    "activations_ = []\n",
    "\n",
    "results_ = []\n",
    "\n",
    "\n",
    "for i in range(25):\n",
    "    try:\n",
    "        epoch = choice(epochs)\n",
    "        neurons_number = choice(neurons_numbers)\n",
    "        layers_number = choice(layers_numbers)\n",
    "        activation = choice(activations)\n",
    "\n",
    "        model = build_model(layers_number=layers_number, \n",
    "                    activation=activation,\n",
    "                    neurons_in_layer=neurons_number)\n",
    "\n",
    "        r = learn_evaluate_many_times(model=model, \n",
    "                              optimizer='adam',\n",
    "                              metrics=['accuracy'],\n",
    "                              epochs=epoch,\n",
    "                              runs=5)\n",
    "        epochs_.append(epoch)\n",
    "        neurons_numbers_.append(neurons_number)\n",
    "        layers_numbers_.append(layers_number)\n",
    "        activations_.append(activation)\n",
    "\n",
    "        results_.append(r)\n",
    "        print('RESULTS:', {'epoch': epoch,\n",
    "               'neurons_number': neurons_number,\n",
    "               'layers_number': layers_number,\n",
    "               'activation': activation, \n",
    "               'mean_accuracy': r[0],\n",
    "               'accuracy_std': r[1]})\n",
    "    except:\n",
    "        print(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'epochs': epochs_,\n",
    "                       'neurons_number': neurons_numbers_,\n",
    "                       'layers_number': layers_numbers_,\n",
    "                       'activation': activations_,\n",
    "                       'mean_accuracy': [val[0] for val in results_],\n",
    "                       'accuracy_std': [val[1] for val in results_]})\n",
    "\n",
    "results.sort_values(by='mean_accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.hist(results['mean_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Влияние параметров.\n",
    "def param_impact(param, results):\n",
    "    less = results.loc[results[param] < results[param].mean(), 'mean_accuracy'].mean()\n",
    "    more = results.loc[results[param] > results[param].mean(), 'mean_accuracy'].mean()\n",
    "    \n",
    "    return round(less, 4), round(more, 4), round((more - less) / less, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "results.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print('epochs', param_impact('epochs', results))\n",
    "print('neurons_number', param_impact('neurons_number', results))\n",
    "print('layers_number', param_impact('layers_number', results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Результаты выглядят не соответствующими стандартным закоромерностям, что связано, вероятно, с малым кол-вом прогонов и смещенными выборками по тем признакам, которые не участвовали в разделении при оценке влияния параметра."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "results.groupby('activation').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Какими бы нерепрезентативными не были выборки, но, похоже, softmax никак не годится для внутренних слоев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "results.sort_values(by='mean_accuracy', ascending=False).head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Выводы:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Baseline metrics (mean accuracy, accuracy std): (0.8704, 0.0049)\n",
    "best learn metrics (mean accuracy, accuracy std): (0.8886, 0.0006)\n",
    "\n",
    "Точность выросла почти на 2%, и существенно упал разброс модели.\n",
    "\n",
    "Росту качества модели способствовали факторы:\n",
    "- увеличение числа эпох обучения,\n",
    "- увеличение числа нейронов в слое."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Task_2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Поработайте с документацией TensorFlow 2. Попробуйте найти полезные команды TensorFlow,  не разобранные на уроке."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1.\n",
    "Клонировать модель (создать копию).\n",
    "\n",
    "tf.keras.models.clone_model(\n",
    "    model, input_tensors=None, clone_function=None)\n",
    "\n",
    "2.\n",
    "Расположение предобученных нейросетей.\n",
    "\n",
    "tf.keras.applications\n",
    "\n",
    "3.\n",
    "Модуль для работы с изображениями.\n",
    "\n",
    "tf.image\n",
    "\n",
    "и в частности метод для изменения размера изображения: \n",
    "\n",
    "tf.image.resize(\n",
    "    images, size, method=ResizeMethod.BILINEAR, preserve_aspect_ratio=False,\n",
    "    antialias=False, name=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Task_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Попробуйте обучить нейронную сеть на TensorFlow 2 на датасете imdb_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### EDA:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Получаем данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "imdb = keras.datasets.imdb\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data), type(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000,), (25000,))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000,), (25000,))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 218)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data[0]), len(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 189)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data[1]), len(train_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 562)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data[7]), len(train_data[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0, 1, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Дата-сет - массив списков разной длины."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "word_index = imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Смотрю среднюю длину (кол-во слов) одного текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238.71364\n",
      "Wall time: 12 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def calc_mean_len(arr):\n",
    "    lengths = []\n",
    "    for a in arr:\n",
    "        lengths.append(len(a))\n",
    "    lengths = np.array(lengths)\n",
    "    print(lengths.mean())\n",
    "        \n",
    "calc_mean_len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_data = keras.preprocessing.sequence.pad_sequences(train_data, value=0, padding='post', maxlen=238)\n",
    "test_data = keras.preprocessing.sequence.pad_sequences(test_data, value=0, padding='post', maxlen=238)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(238, 238, 238)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[0]), len(train_data[1]), len(train_data[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Learn model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples\n",
      "25000/25000 [==============================] - 3s 137us/sample - loss: 32.7086 - accuracy: 0.4990\n",
      "25000/25000 [==============================] - 2s 60us/sample - loss: 0.7074 - accuracy: 0.5009\n",
      "train_accuracy 0.5009\n",
      "25000/25000 [==============================] - 1s 53us/sample - loss: 1.0198 - accuracy: 0.4992\n",
      "test_accuracy 0.5149\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(100, activation='relu', input_shape=(238,)),\n",
    "    keras.layers.Dense(5, activation='relu'),\n",
    "#     keras.layers.Dense(256, activation='relu'),\n",
    "#     keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(2)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_data, train_labels, epochs=1,  verbose=1)\n",
    "\n",
    "train_loss, train_acc = model.evaluate(train_data,  train_labels, verbose=1)\n",
    "print('train_accuracy', round(train_acc, 4))\n",
    "\n",
    "test_loss, tes_acc = model.evaluate(test_data,  test_labels, verbose=1)\n",
    "print('test_accuracy', round(test_acc, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Выводы:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Как-то подозрительно стабильно получается результат 0,5149 на отложенной выборке. И ничем его оттуда не сдвинуть, похоже, где-то ошибка, интересно где?"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "notify_time": "10",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "191.447px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
